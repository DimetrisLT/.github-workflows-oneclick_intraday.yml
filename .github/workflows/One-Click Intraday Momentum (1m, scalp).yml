on:
  workflow_dispatch:
import argparse, os, warnings
import numpy as np, pandas as pd, yfinance as yf
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import HistGradientBoostingClassifier
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
from src.indicators_intraday import feature_table

warnings.filterwarnings("ignore")

# --------- bendros pagalbinės ---------
def _flatten_cols(cols):
    if isinstance(cols, pd.MultiIndex):
        return ["_".join([str(x) for x in tup if str(x) != ""]).strip() for tup in cols]
    return [str(c) for c in cols]

def _normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = pd.DataFrame(df)
    df.columns = _flatten_cols(df.columns)
    df.columns = [str(c).strip().lower() for c in df.columns]

    # datetime garantija
    if "datetime" not in df.columns:
        alt = next((c for c in ("date","time","timestamp","datetimestamp") if c in df.columns), None)
        if alt is not None:
            df["datetime"] = pd.to_datetime(df[alt], errors="coerce", utc=True)
        elif isinstance(df.index, pd.DatetimeIndex):
            df = df.reset_index().rename(columns={"index": "datetime"})
        else:
            try:
                df["datetime"] = pd.to_datetime(df.index, errors="coerce", utc=True)
            except Exception:
                df = df.reset_index()
                df["datetime"] = pd.to_datetime(df.iloc[:, 0], errors="coerce", utc=True)

    if "datetime" not in df.columns:
        df = df.reset_index().rename(columns={"index": "datetime"})
        df["datetime"] = pd.to_datetime(df["datetime"], errors="coerce", utc=True)

    df = df[df["datetime"].notna()]
    return df

# --------- duomenų parsisiuntimas ---------
def dl(ticker, period, interval):
    df = yf.download(ticker, period=period, interval=interval,
                     auto_adjust=True, prepost=True, progress=False)
    if df is None or len(df) == 0:
        return pd.DataFrame(columns=["datetime", "open", "high", "low", "close", "volume"])

    df = _normalize_columns(df)

    # jei close dar neatsirado – bandome alternatyvas
    cols = [str(c).lower() for c in df.columns]
    df.columns = cols
    if "close" not in df.columns:
        if "adj close" in df.columns:
            df["close"] = pd.to_numeric(df["adj close"], errors="coerce")
        else:
            cand = next((c for c in df.columns if "close" in c), None)
            if cand is not None:
                df["close"] = pd.to_numeric(df[cand], errors="coerce")

    keep = ["datetime"] + [c for c in ["open", "high", "low", "close", "volume"] if c in df.columns]
    df = df[keep]

    # tipai ir dublikatai
    df = df.loc[:, ~df.columns.duplicated()]

    def _to_num_safe(obj):
        if isinstance(obj, pd.DataFrame):
            obj = obj.iloc[:, 0]
        return pd.to_numeric(getattr(obj, "squeeze", lambda: obj)(), errors="coerce")

    for c in ["open", "high", "low", "close", "volume"]:
        if c in df.columns:
            df[c] = _to_num_safe(df[c])

    df = df.sort_values("datetime").drop_duplicates()
    return df

# --------- žymės ---------
def build_labels(df, horizon, thr):
    y_fwd = df["close"].shift(-horizon) / df["close"] - 1.0
    label = np.where(y_fwd >= thr, 1, np.where(y_fwd <= -thr, -1, 0))
    return y_fwd, label

# --------- main ---------
def main(args):
    os.makedirs("out", exist_ok=True)
    tickers = [t.strip().upper() for t in args.tickers.split(",")]
    horizon = int(args.horizon); thr = float(args.thr); prob_th = float(args.prob_th)

    summary = []
    for tkr in tickers:
        print(f"=== {tkr} | {args.interval} | period={args.period} | horizon={horizon}min | thr={thr}")
        raw = dl(tkr, args.period, args.interval)
        if raw.empty or "close" not in raw.columns:
            print(f"⚠️ {tkr}: tušti arba be 'close' duomenys, praleidžiu.")
            continue

        feats = feature_table(raw)
        if feats.empty or "close" not in feats.columns:
            print(f"⚠️ {tkr}: nepavyko sudaryti feature’ų (nėra 'close'), praleidžiu.")
            continue

        y_fwd, label = build_labels(feats, horizon, thr)
        data = feats.copy()
        data["y_fwd"] = y_fwd
        data["label"] = label
        data = data.dropna().reset_index(drop=True)

        if len(data) < 200:
            print(f"⚠️ {tkr}: per mažai eilučių ({len(data)}). Praleidžiu.")
            continue

        if len(data) < 1000:
            split = int(len(data) * 0.8)
        else:
            last = data["datetime"].dt.date.iloc[-1]
            prev = data[data["datetime"].dt.date < last]
            split = len(prev) if len(prev) > 400 else int(len(data) * 0.85)

        tr = data.iloc[:split].copy()
        te = data.iloc[split:].copy()

        feat_cols = [c for c in feats.columns if c != "datetime"]
        scaler = StandardScaler()
        Xtr = scaler.fit_transform(tr[feat_cols])
        Xte = scaler.transform(te[feat_cols])

        clf = HistGradientBoostingClassifier(max_depth=6, learning_rate=0.07,
                                             l2_regularization=0.0, max_iter=300)
        clf.fit(Xtr, tr["label"])
        proba = clf.predict_proba(Xte)
        classes = clf.classes_
        idx_up = list(classes).index(1) if 1 in classes else None
        idx_dn = list(classes).index(-1) if -1 in classes else None
        ypred = clf.predict(Xte)

        te["pred_label"] = ypred
        te["prob_up"] = proba[:, idx_up] if idx_up is not None else 0.0
        te["prob_dn"] = proba[:, idx_dn] if idx_dn is not None else 0.0
        te["signal"] = "HOLD"
        te.loc[(te["pred_label"] == 1) & (te["prob_up"] >= prob_th), "signal"] = "BUY"
        te.loc[(te["pred_label"] == -1) & (te["prob_dn"] >= prob_th), "signal"] = "SELL"

        rep = classification_report(te["label"], te["pred_label"], output_dict=True, zero_division=0)
        cm  = confusion_matrix(te["label"], te["pred_label"], labels=[-1, 0, 1])
        acc_all = rep["accuracy"]
        active = te[te["signal"] != "HOLD"]
        acc_act = (active["label"] == active["pred_label"]).mean() if len(active) > 0 else np.nan

        print(f"{tkr} accuracy(all)={acc_all:.3f}, accuracy(active)={acc_act:.3f}")
        print("Confusion matrix [-1,0,1]:", cm)

        out = te[["datetime", "close", "label", "y_fwd", "pred_label", "prob_up", "prob_dn", "signal"]].copy()
        out.to_csv(f"out/preds_intraday_{tkr}.csv", index=False)

        dlast = out["datetime"].dt.date.iloc[-1]
        show = out[out["datetime"].dt.date == dlast].copy()

        plt.figure(figsize=(11, 4), dpi=140)
        plt.plot(show["datetime"], show["y_fwd"], label=f"Realus {horizon}m pokytis")
        plt.plot(
            show["datetime"],
            np.where(show["pred_label"] == 1, thr, np.where(show["pred_label"] == -1, -thr, 0.0)),
            label="Prognozuota (±thr)", alpha=0.8
        )
        plt.axhline(thr, ls="--", alpha=.4); plt.axhline(-thr, ls="--", alpha=.4); plt.axhline(0, ls=":", color="gray")
        for s, c in [("BUY", "green"), ("SELL", "red")]:
            m = show[show["signal"] == s]
            plt.scatter(m["datetime"], np.zeros(len(m)), label=s, s=18, color=c)
        plt.title(f"{tkr} | acc(all)={acc_all:.2%} active={acc_act:.2%}")
        plt.legend(); plt.tight_layout()
        plt.savefig(f"out/intraday_{tkr}.png"); plt.close()

        summary.append([tkr, len(out), float(acc_all), float(acc_act), float(thr), float(prob_th)])

    pd.DataFrame(summary, columns=["ticker","n_test","acc_all","acc_active","thr","prob_th"])\
      .to_csv("out/summary_intraday.csv", index=False)

if __name__ == "__main__":
    ap = argparse.ArgumentParser()
    ap.add_argument("--tickers",  type=str, default="OPEN,PLTR")
    ap.add_argument("--period",   type=str, default="7d")
    ap.add_argument("--interval", type=str, default="1m")
    ap.add_argument("--horizon",  type=str, default="15")
    ap.add_argument("--thr",      type=str, default="0.005")
    ap.add_argument("--prob_th",  type=str, default="0.55")
    args = ap.parse_args()
    main(args)
